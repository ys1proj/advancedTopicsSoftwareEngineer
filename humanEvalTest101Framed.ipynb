{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "c:\\Users\\ysch2\\Documents\\GitHub\\advancedTopicsSoftwareEngineer\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1885: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'Hi, my name is John'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "    \"\"\"\n",
      "    return words_string_framed(s).split(None, 1)\n",
      "\n",
      "\n",
      "def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious\n",
      "Expected: ['Hi', 'my', 'name', 'is', 'John']\n",
      "\n",
      "\n",
      "Input: 'One, two, three, four, five, six'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "    \"\"\"\n",
      "    return words_string_framed(s).split(None, 1)\n",
      "\n",
      "\n",
      "def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious\n",
      "Expected: ['One', 'two', 'three', 'four', 'five', 'six']\n",
      "\n",
      "\n",
      "Input: 'Hi, my name'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "    \"\"\"\n",
      "    return words_string_framed(s).split(None, 1)\n",
      "\n",
      "\n",
      "def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious\n",
      "Expected: ['Hi', 'my', 'name']\n",
      "\n",
      "\n",
      "Input: 'One,, two, three, four, five, six,'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "    \"\"\"\n",
      "    return words_string_framed(s).split(None, 1)\n",
      "\n",
      "\n",
      "def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious\n",
      "Expected: ['One', 'two', 'three', 'four', 'five', 'six']\n",
      "\n",
      "\n",
      "Input: ''\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "    \"\"\"\n",
      "    return words_string_framed(s).split(None, 1)\n",
      "\n",
      "\n",
      "def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious\n",
      "Expected: []\n",
      "\n",
      "\n",
      "Input: 'ahmed , gamal'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "    \"\"\"\n",
      "    return words_string_framed(s).split(None, 1)\n",
      "\n",
      "\n",
      "def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious\n",
      "Expected: ['ahmed', 'gamal']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "###  #HumanEval #101 Model Test for Framing Effect Prompt ###\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model_name = \"finegptproject/humaneval_SFTTrainer_model\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define the framing effect prompt\n",
    "prompt_framed = (\n",
    "    \"def words_string_framed(s):\\n\"\n",
    "    \"    \\\"\\\"\\\"\\n\"\n",
    "    \"    You will be given a string of words, which may be seen as a harmonious collection of thoughts, \"\n",
    "    \"separated by commas or spaces. Your task is to split this harmonious string into individual words, \"\n",
    "    \"each carrying its unique meaning and return an array of these words.\\n\"\n",
    ")\n",
    "\n",
    "# Test cases for the framing effect prompt\n",
    "test_cases_framed = [\n",
    "    (\"Hi, my name is John\", [\"Hi\", \"my\", \"name\", \"is\", \"John\"]),\n",
    "    (\"One, two, three, four, five, six\", [\"One\", \"two\", \"three\", \"four\", \"five\", \"six\"]),\n",
    "    (\"Hi, my name\", [\"Hi\", \"my\", \"name\"]),\n",
    "    (\"One,, two, three, four, five, six,\", [\"One\", \"two\", \"three\", \"four\", \"five\", \"six\"]),\n",
    "    (\"\", []),\n",
    "    (\"ahmed , gamal\", [\"ahmed\", \"gamal\"])\n",
    "]\n",
    "\n",
    "def run_test_cases(test_cases):\n",
    "    for s, expected in test_cases:\n",
    "        inputs_encoded = tokenizer(prompt_framed, return_tensors='pt')\n",
    "\n",
    "        # Generate the output with a limit on max_length to reduce irrelevant content\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs_encoded, max_length=150, num_return_sequences=1)\n",
    "\n",
    "        output_str = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        print(f\"Input: '{s}'\")\n",
    "        print(f\"Model Output: {output_str}\")\n",
    "        print(f\"Expected: {expected}\\n\\n\")\n",
    "\n",
    "# Run the test cases for the framing effect prompt\n",
    "run_test_cases(test_cases_framed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysch2\\Documents\\GitHub\\advancedTopicsSoftwareEngineer\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'Hi, my name is John'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def __init__ ( self, words, commas, spaces ):\n",
      "\n",
      "self.words = words\n",
      "\n",
      "self.commas = spaces\n",
      "\n",
      "self.words.append(words)\n",
      "\n",
      "def __str__ ( self, word, commas, spaces ):\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "Return a list of words that are the same as the given\n",
      "Expected: ['Hi', 'my', 'name', 'is', 'John']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'One, two, three, four, five, six'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def __init__ ( self, words, commas, spaces ):\n",
      "\n",
      "self.words = words\n",
      "\n",
      "self.commas = spaces\n",
      "\n",
      "self.words.append(words)\n",
      "\n",
      "def __str__ ( self, word, commas, spaces ):\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "Return a list of words that are the same as the given\n",
      "Expected: ['One', 'two', 'three', 'four', 'five', 'six']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'Hi, my name'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def __init__ ( self, words, commas, spaces ):\n",
      "\n",
      "self.words = words\n",
      "\n",
      "self.commas = spaces\n",
      "\n",
      "self.words.append(words)\n",
      "\n",
      "def __str__ ( self, word, commas, spaces ):\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "Return a list of words that are the same as the given\n",
      "Expected: ['Hi', 'my', 'name']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'One,, two, three, four, five, six,'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def __init__ ( self, words, commas, spaces ):\n",
      "\n",
      "self.words = words\n",
      "\n",
      "self.commas = spaces\n",
      "\n",
      "self.words.append(words)\n",
      "\n",
      "def __str__ ( self, word, commas, spaces ):\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "Return a list of words that are the same as the given\n",
      "Expected: ['One', 'two', 'three', 'four', 'five', 'six']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ''\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def __init__ ( self, words, commas, spaces ):\n",
      "\n",
      "self.words = words\n",
      "\n",
      "self.commas = spaces\n",
      "\n",
      "self.words.append(words)\n",
      "\n",
      "def __str__ ( self, word, commas, spaces ):\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "Return a list of words that are the same as the given\n",
      "Expected: []\n",
      "\n",
      "\n",
      "Input: 'ahmed , gamal'\n",
      "Model Output: def words_string_framed(s):\n",
      "    \"\"\"\n",
      "    You will be given a string of words, which may be seen as a harmonious collection of thoughts, separated by commas or spaces. Your task is to split this harmonious string into individual words, each carrying its unique meaning and return an array of these words.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def __init__ ( self, words, commas, spaces ):\n",
      "\n",
      "self.words = words\n",
      "\n",
      "self.commas = spaces\n",
      "\n",
      "self.words.append(words)\n",
      "\n",
      "def __str__ ( self, word, commas, spaces ):\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "Return a list of words that are the same as the given\n",
      "Expected: ['ahmed', 'gamal']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "###  #HumanEval #101 GPT-2 Test for Framing Effect Prompt ###\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model_name = \"gpt2\" \n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Define the framing effect prompt\n",
    "prompt_framed = (\n",
    "    \"def words_string_framed(s):\\n\"\n",
    "    \"    \\\"\\\"\\\"\\n\"\n",
    "    \"    You will be given a string of words, which may be seen as a harmonious collection of thoughts, \"\n",
    "    \"separated by commas or spaces. Your task is to split this harmonious string into individual words, \"\n",
    "    \"each carrying its unique meaning and return an array of these words.\\n\"\n",
    ")\n",
    "\n",
    "# Test cases for the framing effect prompt\n",
    "test_cases_framed = [\n",
    "    (\"Hi, my name is John\", [\"Hi\", \"my\", \"name\", \"is\", \"John\"]),\n",
    "    (\"One, two, three, four, five, six\", [\"One\", \"two\", \"three\", \"four\", \"five\", \"six\"]),\n",
    "    (\"Hi, my name\", [\"Hi\", \"my\", \"name\"]),\n",
    "    (\"One,, two, three, four, five, six,\", [\"One\", \"two\", \"three\", \"four\", \"five\", \"six\"]),\n",
    "    (\"\", []),\n",
    "    (\"ahmed , gamal\", [\"ahmed\", \"gamal\"])\n",
    "]\n",
    "\n",
    "def run_test_cases(test_cases):\n",
    "    for s, expected in test_cases:\n",
    "        inputs_encoded = tokenizer(prompt_framed, return_tensors='pt')\n",
    "\n",
    "        # Generate the output with a limit on max_length to reduce irrelevant content\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs_encoded, max_length=150, num_return_sequences=1)\n",
    "\n",
    "        output_str = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        print(f\"Input: '{s}'\")\n",
    "        print(f\"Model Output: {output_str}\")\n",
    "        print(f\"Expected: {expected}\\n\\n\")\n",
    "\n",
    "# Run the test cases for the framing effect prompt\n",
    "run_test_cases(test_cases_framed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
